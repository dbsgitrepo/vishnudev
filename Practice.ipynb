{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b7649980-6d9d-4025-a992-b4918eb90778",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "697c7276-f153-4549-892c-4d262c363776",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = [\n",
    "    (1, \"Alice\", 29),\n",
    "    (2, \"Bob\", 35),\n",
    "    (3, \"Charlie\", 40)\n",
    "]\n",
    "\n",
    "columns = [\"id\", \"name\", \"age\"]\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Define Delta Table path in DBFS\n",
    "delta_path = \"dbfs:/mnt/delta/my_delta_table\"\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af3161b7-e04f-42ee-b6d9-9d999a7a09f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "new_data = [(5, \"Eve\", 32)]  # Add your new row here\n",
    "columns = [\"id\", \"name\", \"age\"]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_new = spark.createDataFrame(new_data, columns)\n",
    "\n",
    "# Define Delta Table path\n",
    "delta_path = \"dbfs:/mnt/delta/my_delta_table\"\n",
    "\n",
    "# Append the new row to the existing Delta Table\n",
    "df_new.write.format(\"delta\").mode(\"append\").save(delta_path)\n",
    "\n",
    "print(\"New row inserted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86fd4e41-ec3d-4f8e-84d2-0c481841955a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_delta = spark.read.format(\"delta\").load(delta_path)\n",
    "df_delta.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7e26b65-015d-482f-8e69-819091090ce5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df = spark.read.format(\"delta\").load(delta_path)\n",
    "\n",
    "# Add a new column 'city' with a default value\n",
    "df = df.withColumn(\"city\", lit(\"Unknown\"))\n",
    "\n",
    "# Overwrite the Delta table with the new structure and enable schema evolution\n",
    "df.write.format(\"delta\").mode(\"overwrite\").option(\"mergeSchema\", \"true\").save(delta_path)\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32529e88-233f-48a9-96a6-a93e58cc21c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_filtered = spark.read.format(\"delta\").load(delta_path).filter(\"age > 30\")\n",
    "df_filtered.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Practice",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
